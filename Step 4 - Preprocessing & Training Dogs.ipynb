{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Training\n",
    "\n",
    "### Goal:\n",
    "<p>Create a cleaned development dataset you can use to complete the modeling step of your project.</p>\n",
    "\n",
    "### Steps:\n",
    "<ul><li>Create dummy or indicator features for categorical variables</li><li>Standardize the magnitude of numeric features using a scaler</li><li>Split into testing and training datasets</li></ul>\n",
    "Review the following questions and apply them to your dataset:<ul><li>Does my data set have any categorical data, such as Gender or day of the week?</li><li>Do my features have data values that range from 0 - 100 or 0-1 or both and more?  </li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "\n",
    "from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7179 entries, 0 to 7178\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   age                    7179 non-null   object \n",
      " 1   gender                 7179 non-null   object \n",
      " 2   size                   7179 non-null   object \n",
      " 3   coat                   7179 non-null   object \n",
      " 4   distance               7179 non-null   float64\n",
      " 5   spayed_neutered        7179 non-null   bool   \n",
      " 6   house_trained          7179 non-null   bool   \n",
      " 7   special_needs          7179 non-null   bool   \n",
      " 8   shots_current          7179 non-null   bool   \n",
      " 9   breed_primary          7179 non-null   object \n",
      " 10  breed_secondary        7179 non-null   object \n",
      " 11  breed_mixed            7179 non-null   bool   \n",
      " 12  color_primary          7179 non-null   object \n",
      " 13  color_secondary        7179 non-null   object \n",
      " 14  color_tertiary         7179 non-null   object \n",
      " 15  goodwith_children      7179 non-null   object \n",
      " 16  goodwith_dogs          7179 non-null   object \n",
      " 17  goodwith_cats          7179 non-null   object \n",
      " 18  hasimage               7179 non-null   bool   \n",
      " 19  hasvideo               7179 non-null   bool   \n",
      " 20  duration_as_adoptable  7179 non-null   float64\n",
      " 21  city                   7179 non-null   object \n",
      " 22  population             7179 non-null   float64\n",
      "dtypes: bool(7), float64(3), object(13)\n",
      "memory usage: 946.6+ KB\n"
     ]
    }
   ],
   "source": [
    "adopted = pd.read_csv('data/dogs_trimmed.csv')\n",
    "adopted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies!\n",
    "### After converting bools to ints, of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df = adopted[['gender', 'size', 'coat', 'duration_as_adoptable', 'hasimage', 'hasvideo', 'spayed_neutered', 'house_trained', 'special_needs', 'shots_current', 'goodwith_children', 'goodwith_dogs', 'goodwith_cats']]\n",
    "df.loc[:, ['hasimage', 'hasvideo', 'spayed_neutered', 'house_trained', 'special_needs', 'shots_current']] = adopted.loc[:, ['hasimage', 'hasvideo', 'spayed_neutered', 'house_trained', 'special_needs', 'shots_current']].astype('int64')\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one of each of the dummy category columns so those features don't double-weight anything\n",
    "df.drop(['size_Extra Large', 'gender_Female', 'coat_Hairless', 'goodwith_children_False', 'goodwith_dogs_False', 'goodwith_cats_False'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputed = imp.fit_transform(df)\n",
    "df = pd.DataFrame(imputed, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling using StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_as_adoptable</th>\n",
       "      <th>hasimage</th>\n",
       "      <th>hasvideo</th>\n",
       "      <th>spayed_neutered</th>\n",
       "      <th>house_trained</th>\n",
       "      <th>special_needs</th>\n",
       "      <th>shots_current</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>size_Large</th>\n",
       "      <th>size_Medium</th>\n",
       "      <th>size_Small</th>\n",
       "      <th>coat_Curly</th>\n",
       "      <th>coat_Long</th>\n",
       "      <th>coat_Medium</th>\n",
       "      <th>coat_Short</th>\n",
       "      <th>coat_Wire</th>\n",
       "      <th>coat_unknown</th>\n",
       "      <th>goodwith_children_True</th>\n",
       "      <th>goodwith_children_unknown</th>\n",
       "      <th>goodwith_dogs_True</th>\n",
       "      <th>goodwith_dogs_unknown</th>\n",
       "      <th>goodwith_cats_True</th>\n",
       "      <th>goodwith_cats_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "      <td>7179.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "      <td>1.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.72250</td>\n",
       "      <td>-8.24796</td>\n",
       "      <td>-0.20295</td>\n",
       "      <td>-1.77474</td>\n",
       "      <td>-0.84534</td>\n",
       "      <td>-0.17402</td>\n",
       "      <td>-3.45810</td>\n",
       "      <td>-1.05633</td>\n",
       "      <td>-0.59735</td>\n",
       "      <td>-0.72447</td>\n",
       "      <td>-0.77941</td>\n",
       "      <td>-0.12589</td>\n",
       "      <td>-0.25614</td>\n",
       "      <td>-0.54392</td>\n",
       "      <td>-1.05367</td>\n",
       "      <td>-0.14103</td>\n",
       "      <td>-0.41713</td>\n",
       "      <td>-0.85824</td>\n",
       "      <td>-0.98356</td>\n",
       "      <td>-1.26237</td>\n",
       "      <td>-0.73793</td>\n",
       "      <td>-0.62833</td>\n",
       "      <td>-1.23031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.58503</td>\n",
       "      <td>0.12124</td>\n",
       "      <td>-0.20295</td>\n",
       "      <td>0.56346</td>\n",
       "      <td>-0.84534</td>\n",
       "      <td>-0.17402</td>\n",
       "      <td>0.28918</td>\n",
       "      <td>-1.05633</td>\n",
       "      <td>-0.59735</td>\n",
       "      <td>-0.72447</td>\n",
       "      <td>-0.77941</td>\n",
       "      <td>-0.12589</td>\n",
       "      <td>-0.25614</td>\n",
       "      <td>-0.54392</td>\n",
       "      <td>-1.05367</td>\n",
       "      <td>-0.14103</td>\n",
       "      <td>-0.41713</td>\n",
       "      <td>-0.85824</td>\n",
       "      <td>-0.98356</td>\n",
       "      <td>-1.26237</td>\n",
       "      <td>-0.73793</td>\n",
       "      <td>-0.62833</td>\n",
       "      <td>-1.23031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.37803</td>\n",
       "      <td>0.12124</td>\n",
       "      <td>-0.20295</td>\n",
       "      <td>0.56346</td>\n",
       "      <td>-0.84534</td>\n",
       "      <td>-0.17402</td>\n",
       "      <td>0.28918</td>\n",
       "      <td>0.94668</td>\n",
       "      <td>-0.59735</td>\n",
       "      <td>-0.72447</td>\n",
       "      <td>-0.77941</td>\n",
       "      <td>-0.12589</td>\n",
       "      <td>-0.25614</td>\n",
       "      <td>-0.54392</td>\n",
       "      <td>0.94906</td>\n",
       "      <td>-0.14103</td>\n",
       "      <td>-0.41713</td>\n",
       "      <td>-0.85824</td>\n",
       "      <td>-0.98356</td>\n",
       "      <td>0.79216</td>\n",
       "      <td>-0.73793</td>\n",
       "      <td>-0.62833</td>\n",
       "      <td>0.81281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.13745</td>\n",
       "      <td>0.12124</td>\n",
       "      <td>-0.20295</td>\n",
       "      <td>0.56346</td>\n",
       "      <td>1.18296</td>\n",
       "      <td>-0.17402</td>\n",
       "      <td>0.28918</td>\n",
       "      <td>0.94668</td>\n",
       "      <td>1.67405</td>\n",
       "      <td>1.38033</td>\n",
       "      <td>1.28302</td>\n",
       "      <td>-0.12589</td>\n",
       "      <td>-0.25614</td>\n",
       "      <td>-0.54392</td>\n",
       "      <td>0.94906</td>\n",
       "      <td>-0.14103</td>\n",
       "      <td>-0.41713</td>\n",
       "      <td>1.16518</td>\n",
       "      <td>1.01672</td>\n",
       "      <td>0.79216</td>\n",
       "      <td>1.35515</td>\n",
       "      <td>1.59153</td>\n",
       "      <td>0.81281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.60134</td>\n",
       "      <td>0.12124</td>\n",
       "      <td>4.92729</td>\n",
       "      <td>0.56346</td>\n",
       "      <td>1.18296</td>\n",
       "      <td>5.74662</td>\n",
       "      <td>0.28918</td>\n",
       "      <td>0.94668</td>\n",
       "      <td>1.67405</td>\n",
       "      <td>1.38033</td>\n",
       "      <td>1.28302</td>\n",
       "      <td>7.94344</td>\n",
       "      <td>3.90411</td>\n",
       "      <td>1.83851</td>\n",
       "      <td>0.94906</td>\n",
       "      <td>7.09074</td>\n",
       "      <td>2.39733</td>\n",
       "      <td>1.16518</td>\n",
       "      <td>1.01672</td>\n",
       "      <td>0.79216</td>\n",
       "      <td>1.35515</td>\n",
       "      <td>1.59153</td>\n",
       "      <td>0.81281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration_as_adoptable   hasimage   hasvideo  spayed_neutered  house_trained  special_needs  shots_current  gender_Male  size_Large  size_Medium  size_Small  coat_Curly  coat_Long  coat_Medium  coat_Short  coat_Wire  coat_unknown  goodwith_children_True  goodwith_children_unknown  goodwith_dogs_True  goodwith_dogs_unknown  goodwith_cats_True  goodwith_cats_unknown\n",
       "count             7179.00000 7179.00000 7179.00000       7179.00000     7179.00000     7179.00000     7179.00000   7179.00000  7179.00000   7179.00000  7179.00000  7179.00000 7179.00000   7179.00000  7179.00000 7179.00000    7179.00000              7179.00000                 7179.00000          7179.00000             7179.00000          7179.00000             7179.00000\n",
       "mean                -0.00000   -0.00000   -0.00000         -0.00000       -0.00000        0.00000       -0.00000     -0.00000     0.00000     -0.00000    -0.00000    -0.00000    0.00000     -0.00000     0.00000    0.00000      -0.00000                -0.00000                   -0.00000            -0.00000               -0.00000             0.00000               -0.00000\n",
       "std                  1.00007    1.00007    1.00007          1.00007        1.00007        1.00007        1.00007      1.00007     1.00007      1.00007     1.00007     1.00007    1.00007      1.00007     1.00007    1.00007       1.00007                 1.00007                    1.00007             1.00007                1.00007             1.00007                1.00007\n",
       "min                 -0.72250   -8.24796   -0.20295         -1.77474       -0.84534       -0.17402       -3.45810     -1.05633    -0.59735     -0.72447    -0.77941    -0.12589   -0.25614     -0.54392    -1.05367   -0.14103      -0.41713                -0.85824                   -0.98356            -1.26237               -0.73793            -0.62833               -1.23031\n",
       "25%                 -0.58503    0.12124   -0.20295          0.56346       -0.84534       -0.17402        0.28918     -1.05633    -0.59735     -0.72447    -0.77941    -0.12589   -0.25614     -0.54392    -1.05367   -0.14103      -0.41713                -0.85824                   -0.98356            -1.26237               -0.73793            -0.62833               -1.23031\n",
       "50%                 -0.37803    0.12124   -0.20295          0.56346       -0.84534       -0.17402        0.28918      0.94668    -0.59735     -0.72447    -0.77941    -0.12589   -0.25614     -0.54392     0.94906   -0.14103      -0.41713                -0.85824                   -0.98356             0.79216               -0.73793            -0.62833                0.81281\n",
       "75%                  0.13745    0.12124   -0.20295          0.56346        1.18296       -0.17402        0.28918      0.94668     1.67405      1.38033     1.28302    -0.12589   -0.25614     -0.54392     0.94906   -0.14103      -0.41713                 1.16518                    1.01672             0.79216                1.35515             1.59153                0.81281\n",
       "max                  5.60134    0.12124    4.92729          0.56346        1.18296        5.74662        0.28918      0.94668     1.67405      1.38033     1.28302     7.94344    3.90411      1.83851     0.94906    7.09074       2.39733                 1.16518                    1.01672             0.79216                1.35515             1.59153                0.81281"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df = pd.DataFrame(scaled, columns=df.columns)\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df.drop(columns='duration_as_adoptable'), \n",
    "                                                    scaled_df.duration_as_adoptable, test_size=0.3, \n",
    "                                                    random_state=192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5025, 22), (2154, 22))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5025,), (2154,))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/dogs_X_train.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/dogs_X_test.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/dogs_y_train.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/dogs_y_test.csv\"\n"
     ]
    }
   ],
   "source": [
    "# save training and test sets\n",
    "datapath = 'data/tt_sets'\n",
    "save_file(X_train, 'dogs_X_train.csv', datapath)\n",
    "save_file(X_test, 'dogs_X_test.csv', datapath)\n",
    "save_file(y_train, 'dogs_y_train.csv', datapath)\n",
    "save_file(y_test, 'dogs_y_test.csv', datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "### Goal: Build two to three different models and identify the best one.\n",
    "<ul><li>Fit your models with a training dataset</li>\n",
    "<li>Review model outcomes — Iterate over additional models as needed</li>\n",
    "<li>Identify the final model that you think is the best model for this project</li></ul>\n",
    " Review the following questions and apply them to your analysis: \n",
    "<ul><li>Does my data involve a time series or forecasting? If so, am I splitting the train and test data appropriately?</li>\n",
    "<li>Is my response variable continuous or categorical?</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do random search x times and choose the params of the best one\n",
    "def random_search_bestof(model, X, y, params, bestof=5):\n",
    "    scores = {}\n",
    "    for f in range(1,bestof+1):\n",
    "        rcv = RandomizedSearchCV(model, param_distributions=params, cv=5, n_jobs=-1)\n",
    "        rcv.fit(X, y)\n",
    "        scores[f] = rcv.best_params_\n",
    "        \n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    return scores_df.mode(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40127805391915394"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07708727,  0.02642567,  0.00046362, -0.04244787,  0.00538001])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv = cross_validate(rf, X_train, y_train, cv=5)\n",
    "rf_cv_scores_preopt = rf_cv['test_score']\n",
    "rf_cv_scores_preopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.017453168922591987, 0.03727916147055712)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rf_cv_scores_preopt), np.std(rf_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.013701\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)\n",
    "rmse_rf_preopt = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "print(\"RMSE : % f\" %(rmse_rf_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 20 Random Searchs: 187.73303294181824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>54.00000</td>\n",
       "      <td>112.00000</td>\n",
       "      <td>233.00000</td>\n",
       "      <td>297.00000</td>\n",
       "      <td>379.00000</td>\n",
       "      <td>483.00000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5          6\n",
       "n_estimators 54.00000 112.00000 233.00000 297.00000 379.00000 483.00000 1000.00000\n",
       "max_depth     5.00000       nan       nan       nan       nan       nan        nan"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "rf_grid_params = {\n",
    "        'n_estimators': n_est,\n",
    "        'max_depth': [1, 2, 3,4,5, 6,7,8,9, 10, None]\n",
    "}\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "\n",
    "# #rf_random_cv = RandomizedSearchCV(rf, param_distributions=grid_params, cv=5, n_jobs=-1)\n",
    "# rf_scores = random_search_bestof(rf, X_train, y_train, rf_grid_params, bestof=20)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Time to run 20 Random Searchs:\", end - start)\n",
    "\n",
    "# rf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 1 Grid Search: 190.73542094230652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'n_estimators': 143}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gcv = GridSearchCV(rf, param_grid=rf_grid_params, cv=5, n_jobs=-1)\n",
    "gcv.fit(X_train, y_train)\n",
    "gcv_params = gcv.best_params_\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"Time to run 1 Grid Search:\", end - start)\n",
    "\n",
    "gcv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18373698561131813"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=gcv_params['n_estimators'], max_depth=gcv_params['max_depth'])\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.07581845, 0.11517325, 0.09567379, 0.08816017, 0.06934185]),\n",
       " array([0.11791643, 0.12160575, 0.12131036, 0.11418095, 0.05970254]))"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_train = cross_validate(rf, X_train, y_train, cv=5)\n",
    "rf_cv_test = cross_validate(rf, X_test, y_test, cv=5)\n",
    "rf_cv_train['test_score'], rf_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.08883350049520959\n",
      "Average CV Score, Trest Set: 0.10694320612665009\n"
     ]
    }
   ],
   "source": [
    "rf_train_score = np.mean(rf_cv_train['test_score'])\n",
    "rf_test_score = np.mean(rf_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", rf_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", rf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.901386\n",
      "RMSE Test Set :  0.955619\n"
     ]
    }
   ],
   "source": [
    "rf_train_pred = rf.predict(X_train)\n",
    "rf_test_pred = rf.predict(X_test)\n",
    "rf_rmse_train = np.sqrt(mean_squared_error(y_train, rf_train_pred))\n",
    "rf_rmse_test = np.sqrt(mean_squared_error(y_test, rf_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(rf_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(rf_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16057548120350285"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10368693, 0.12933564, 0.09639947, 0.09613142, 0.07504663])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv = cross_validate(gb, X_train, y_train, cv=5)\n",
    "gb_cv_scores_preopt = gb_cv['test_score']\n",
    "gb_cv_scores_preopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10012001603647527, 0.017462542766978974)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gb_cv_scores_preopt), np.std(gb_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.947865\n"
     ]
    }
   ],
   "source": [
    "gb_pred = gb.predict(X_test)\n",
    "rmse_gb_preopt = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
    "print(\"RMSE : % f\" %(rmse_gb_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "gb_grid_params = {\n",
    "        'learning_rate': [.01, .1, 1],\n",
    "        'n_estimators': n_est,\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]\n",
    "}\n",
    "\n",
    "# gb_random_cv = RandomizedSearchCV(gb, param_distributions=grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
       "                         'n_estimators': [10, 12, 16, 20, 26, 33, 42, 54, 69,\n",
       "                                          88, 112, 143, 183, 233, 297, 379, 483,\n",
       "                                          615, 784, 1000]})"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid_cv = GridSearchCV(gb, param_grid=gb_grid_params, cv=5, n_jobs=-1)\n",
    "gb_grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X_train)), np.all(np.isfinite(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 233}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid_cv.fit(X_train_n, y_train)\n",
    "gb_grid_cv_params = gb_grid_cv.best_params_\n",
    "\n",
    "gb_grid_cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13482430720837768"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=gb_grid_cv_params['n_estimators'], max_depth=gb_grid_cv_params['max_depth'], learning_rate=gb_grid_cv_params['learning_rate'])\n",
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.09699935, 0.1173686 , 0.12294135, 0.09372287, 0.09057953]),\n",
       " array([0.09354174, 0.13282816, 0.11297745, 0.0943956 , 0.05003416]))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv_train = cross_validate(gb, X_train, y_train, cv=5)\n",
    "gb_cv_test = cross_validate(gb, X_test, y_test, cv=5)\n",
    "gb_cv_train['test_score'], gb_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.10432233800898852\n",
      "Average CV Score, Trest Set: 0.09675542402534765\n"
     ]
    }
   ],
   "source": [
    "gb_train_score = np.mean(gb_cv_train['test_score'])\n",
    "gb_test_score = np.mean(gb_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", gb_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", gb_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.928000\n",
      "RMSE Test Set :  0.948222\n"
     ]
    }
   ],
   "source": [
    "gb_train_pred = gb.predict(X_train)\n",
    "gb_test_pred = gb.predict(X_test)\n",
    "gb_rmse_train = np.sqrt(mean_squared_error(y_train, gb_train_pred))\n",
    "gb_rmse_test = np.sqrt(mean_squared_error(y_test, gb_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(gb_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(gb_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4341712634231919"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsRegressor(n_neighbors=25, weights='distance')\n",
    "kn.fit(X_train, y_train)\n",
    "kn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.03266607198484026, 0.05799061146759032)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_cv = cross_validate(kn, X_train, y_train, cv=5)\n",
    "kn_cv_scores_preopt = kn_cv['test_score']\n",
    "np.mean(kn_cv_scores_preopt), np.std(kn_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.040748\n"
     ]
    }
   ],
   "source": [
    "kn_pred = kn.predict(X_test)\n",
    "rmse_kn_preopt = np.sqrt(mean_squared_error(y_test, kn_pred))\n",
    "print(\"RMSE : % f\" %(rmse_kn_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "kn_grid_params = {\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'n_neighbors': n_est,\n",
    "        'p': [1, 2]\n",
    "}\n",
    "\n",
    "# kn_random_cv = RandomizedSearchCV(kn, param_distributions=grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 33, 'p': 2, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_grid_cv = GridSearchCV(kn, param_grid=kn_grid_params, cv=5, n_jobs=-1)\n",
    "kn_grid_cv.fit(X_train, y_train)\n",
    "kn_grid_cv_params = kn_grid_cv.best_params_\n",
    "\n",
    "kn_grid_cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1479684513025028"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsRegressor(n_neighbors=kn_grid_cv_params['n_neighbors'], weights=kn_grid_cv_params['weights'], p=kn_grid_cv_params['p'])\n",
    "kn.fit(X_train, y_train)\n",
    "kn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.07831157, 0.09797027, 0.1301671 , 0.07876559, 0.07542248]),\n",
       " array([0.04612059, 0.09192267, 0.10018326, 0.03288649, 0.0624876 ]))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_cv_train = cross_validate(kn, X_train, y_train, cv=5)\n",
    "kn_cv_test = cross_validate(kn, X_test, y_test, cv=5)\n",
    "kn_cv_train['test_score'], kn_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.09212740149732099\n",
      "Average CV Score, Trest Set: 0.06672012176651654\n"
     ]
    }
   ],
   "source": [
    "kn_train_score = np.mean(kn_cv_train['test_score'])\n",
    "kn_test_score = np.mean(kn_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", kn_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", kn_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.920923\n",
      "RMSE Test Set :  0.961883\n"
     ]
    }
   ],
   "source": [
    "kn_train_pred = kn.predict(X_train)\n",
    "kn_test_pred = kn.predict(X_test)\n",
    "kn_rmse_train = np.sqrt(mean_squared_error(y_train, kn_train_pred))\n",
    "kn_rmse_test = np.sqrt(mean_squared_error(y_test, kn_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(kn_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(kn_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3427697163946294"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = 50)\n",
    "xg.fit(X_train, y_train)\n",
    "xg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.001412215580556242, 0.021037048338566924)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv = cross_validate(xg, X_train, y_train, cv=5)\n",
    "xg_cv_scores_preopt = xg_cv['test_score']\n",
    "np.mean(xg_cv_scores_preopt), np.std(xg_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.992280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xg_pred = xg.predict(X_test)\n",
    "rmse_xg_preopt = np.sqrt(mean_squared_error(y_test, xg_pred))\n",
    "print(\"RMSE : % f\" %(rmse_xg_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "xg_grid_params = {\n",
    "        'objective': ['reg:squarederror', 'reg:squaredlogerror', 'reg:logistic'],\n",
    "        'n_estimators': n_est,\n",
    "}\n",
    "\n",
    "# xg_random_cv = RandomizedSearchCV(xg, param_distributions=grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10, 'objective': 'reg:squarederror'}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_grid_cv = GridSearchCV(xg, param_grid=xg_grid_params, cv=5, n_jobs=-1)\n",
    "xg_grid_cv.fit(X_train, y_train)\n",
    "xg_grid_cv_params = xg_grid_cv.best_params_\n",
    "\n",
    "xg_grid_cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22847556791179424"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBRegressor(objective=xg_grid_cv_params['objective'], n_estimators = xg_grid_cv_params['n_estimators'])\n",
    "xg.fit(X_train, y_train)\n",
    "xg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.05390593, 0.11673082, 0.08545221, 0.07386612, 0.06445725]),\n",
       " array([ 0.07410784,  0.12084757,  0.09253433,  0.08777601, -0.00657975]))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_train = cross_validate(xg, X_train, y_train, cv=5)\n",
    "xg_cv_test = cross_validate(xg, X_test, y_test, cv=5)\n",
    "xg_cv_train['test_score'], xg_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.07888246514737911\n",
      "Average CV Score, Trest Set: 0.07373719934316328\n"
     ]
    }
   ],
   "source": [
    "xg_train_score = np.mean(xg_cv_train['test_score'])\n",
    "xg_test_score = np.mean(xg_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", xg_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", xg_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.876336\n",
      "RMSE Test Set :  0.960878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xg_train_pred = xg.predict(X_train)\n",
    "xg_test_pred = xg.predict(X_test)\n",
    "xg_rmse_train = np.sqrt(mean_squared_error(y_train, xg_train_pred))\n",
    "xg_rmse_test = np.sqrt(mean_squared_error(y_test, xg_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(xg_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(xg_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV Train</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>CV Test</th>\n",
       "      <th>RMSE Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.08883</td>\n",
       "      <td>0.90139</td>\n",
       "      <td>0.10694</td>\n",
       "      <td>0.95562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.10432</td>\n",
       "      <td>0.92800</td>\n",
       "      <td>0.09676</td>\n",
       "      <td>0.94822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNeighbors</th>\n",
       "      <td>0.09213</td>\n",
       "      <td>0.92092</td>\n",
       "      <td>0.06672</td>\n",
       "      <td>0.96188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.07888</td>\n",
       "      <td>0.87634</td>\n",
       "      <td>0.07374</td>\n",
       "      <td>0.96088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CV Train  RMSE Train  CV Test  RMSE Test\n",
       "RandomForest       0.08883     0.90139  0.10694    0.95562\n",
       "GradientBoosting   0.10432     0.92800  0.09676    0.94822\n",
       "KNNeighbors        0.09213     0.92092  0.06672    0.96188\n",
       "XGBoost            0.07888     0.87634  0.07374    0.96088"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = pd.DataFrame({'CV Train': [np.mean(rf_train_score), np.mean(gb_train_score), np.mean(kn_train_score), np.mean(xg_train_score)], 'RMSE Train': [rf_rmse_train, gb_rmse_train, kn_rmse_train, xg_rmse_train],'CV Test': [np.mean(rf_test_score), np.mean(gb_test_score), np.mean(kn_test_score), np.mean(xg_test_score)], 'RMSE Test': [rf_rmse_test, gb_rmse_test, kn_rmse_test, xg_rmse_test]}, index=['RandomForest', 'GradientBoosting', 'KNNeighbors', 'XGBoost'])\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best CV Score: \n",
      "Train: XGBoost \n",
      "Test: KNNeighbors\n",
      "\n",
      "Model with best RMSE: \n",
      "Train: XGBoost \n",
      "Test: GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "print(\"Model with best CV Score: \\nTrain:\", model_scores['CV Train'].idxmin(), \"\\nTest:\", model_scores['CV Test'].idxmin())\n",
    "print(\"\\nModel with best RMSE: \\nTrain:\", model_scores['RMSE Train'].idxmin(), \"\\nTest:\", model_scores['RMSE Test'].idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['RandomForest', 'GradientBoosting', 'KNNeighbors', 'XGBoost','RandomForest', 'GradientBoosting', 'KNNeighbors', 'XGBoost']\n",
    "cv_scores_all = [np.mean(rf_train_score), np.mean(gb_train_score), np.mean(kn_train_score), np.mean(xg_train_score), np.mean(rf_test_score), np.mean(gb_test_score), np.mean(kn_test_score), np.mean(xg_test_score)]\n",
    "types = ['train', 'train', 'train', 'train', 'test', 'test', 'test', 'test']\n",
    "rmse_scores_all = [rf_rmse_train, gb_rmse_train, kn_rmse_train, xg_rmse_train, rf_rmse_test, gb_rmse_test, kn_rmse_test, xg_rmse_test]\n",
    "\n",
    "cv_scores = pd.DataFrame(list(zip(models, cv_scores_all, types)), \n",
    "               columns =['Model', 'Scores', 'Type' ]) \n",
    "rmse_scores = pd.DataFrame(list(zip(models, rmse_scores_all, types)), \n",
    "               columns =['Model', 'Scores', 'Type' ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig=plt.subplots(figsize=(10, 5))\n",
    "sns.barplot(x='Model', y='Scores', hue='Type', data=cv_scores)\n",
    "plt.title(\"CV Score Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.subplots(figsize=(10, 5))\n",
    "sns.barplot(x='Model', y='Scores', hue='Type', data=rmse_scores)\n",
    "plt.title(\"RMSE Score Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to go forward with **GradientBoosting** for the dogs data. I'm choosing this model because it has the best RMSE score for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
