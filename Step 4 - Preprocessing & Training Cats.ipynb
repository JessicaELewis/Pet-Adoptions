{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Training\n",
    "\n",
    "### Goal:\n",
    "<p>Create a cleaned development dataset you can use to complete the modeling step of your project.</p>\n",
    "\n",
    "### Steps:\n",
    "<ul><li>Create dummy or indicator features for categorical variables</li><li>Standardize the magnitude of numeric features using a scaler</li><li>Split into testing and training datasets</li></ul>\n",
    "Review the following questions and apply them to your dataset:<ul><li>Does my data set have any categorical data, such as Gender or day of the week?</li><li>Do my features have data values that range from 0 - 100 or 0-1 or both and more? Â </li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "\n",
    "from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6489 entries, 0 to 6488\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   age                    6489 non-null   object \n",
      " 1   gender                 6489 non-null   object \n",
      " 2   size                   6489 non-null   object \n",
      " 3   coat                   6489 non-null   object \n",
      " 4   distance               6489 non-null   float64\n",
      " 5   spayed_neutered        6489 non-null   bool   \n",
      " 6   house_trained          6489 non-null   bool   \n",
      " 7   declawed               6489 non-null   bool   \n",
      " 8   special_needs          6489 non-null   bool   \n",
      " 9   shots_current          6489 non-null   bool   \n",
      " 10  breed_primary          6489 non-null   object \n",
      " 11  breed_secondary        6489 non-null   object \n",
      " 12  breed_mixed            6489 non-null   bool   \n",
      " 13  breed_unknown          6489 non-null   bool   \n",
      " 14  color_primary          6489 non-null   object \n",
      " 15  color_secondary        6489 non-null   object \n",
      " 16  color_tertiary         6489 non-null   object \n",
      " 17  goodwith_children      6489 non-null   object \n",
      " 18  goodwith_dogs          6489 non-null   object \n",
      " 19  goodwith_cats          6489 non-null   object \n",
      " 20  hasimage               6489 non-null   bool   \n",
      " 21  hasvideo               6489 non-null   bool   \n",
      " 22  duration_as_adoptable  6489 non-null   float64\n",
      " 23  city                   6489 non-null   object \n",
      " 24  population             6489 non-null   float64\n",
      "dtypes: bool(9), float64(3), object(13)\n",
      "memory usage: 868.3+ KB\n"
     ]
    }
   ],
   "source": [
    "adopted = pd.read_csv('data/cats_trimmed.csv')\n",
    "adopted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies!\n",
    "### After converting bools to ints, of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df = adopted[['gender', 'size', 'coat', 'duration_as_adoptable', 'hasimage', 'hasvideo', 'spayed_neutered', 'house_trained', 'declawed', 'special_needs', 'shots_current', 'goodwith_children', 'goodwith_dogs', 'goodwith_cats']]\n",
    "df.loc[:, ['hasimage', 'hasvideo', 'spayed_neutered', 'house_trained', 'declawed', 'special_needs', 'shots_current']] = adopted.loc[:, ['hasimage', 'hasvideo', 'spayed_neutered', 'house_trained', 'declawed', 'special_needs', 'shots_current']].astype('int64')\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one of each of the dummy category columns so those features don't double-weight anything\n",
    "df.drop(['size_Extra Large', 'gender_Female', 'coat_Hairless', 'goodwith_children_False', 'goodwith_dogs_False', 'goodwith_cats_False'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputed = imp.fit_transform(df)\n",
    "df = pd.DataFrame(imputed, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling using StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_as_adoptable</th>\n",
       "      <th>hasimage</th>\n",
       "      <th>hasvideo</th>\n",
       "      <th>spayed_neutered</th>\n",
       "      <th>house_trained</th>\n",
       "      <th>declawed</th>\n",
       "      <th>special_needs</th>\n",
       "      <th>shots_current</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>size_Large</th>\n",
       "      <th>size_Medium</th>\n",
       "      <th>size_Small</th>\n",
       "      <th>coat_Long</th>\n",
       "      <th>coat_Medium</th>\n",
       "      <th>coat_Short</th>\n",
       "      <th>coat_unknown</th>\n",
       "      <th>goodwith_children_True</th>\n",
       "      <th>goodwith_children_unknown</th>\n",
       "      <th>goodwith_dogs_True</th>\n",
       "      <th>goodwith_dogs_unknown</th>\n",
       "      <th>goodwith_cats_True</th>\n",
       "      <th>goodwith_cats_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "      <td>6489.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "      <td>1.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.69010</td>\n",
       "      <td>-5.38903</td>\n",
       "      <td>-0.19213</td>\n",
       "      <td>-2.86887</td>\n",
       "      <td>-1.26894</td>\n",
       "      <td>-0.09497</td>\n",
       "      <td>-0.13900</td>\n",
       "      <td>-4.48741</td>\n",
       "      <td>-0.95730</td>\n",
       "      <td>-0.29454</td>\n",
       "      <td>-1.90570</td>\n",
       "      <td>-0.38825</td>\n",
       "      <td>-0.30067</td>\n",
       "      <td>-0.37793</td>\n",
       "      <td>-1.76561</td>\n",
       "      <td>-0.18909</td>\n",
       "      <td>-0.60340</td>\n",
       "      <td>-1.36886</td>\n",
       "      <td>-0.49136</td>\n",
       "      <td>-1.71113</td>\n",
       "      <td>-0.98213</td>\n",
       "      <td>-0.92987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.59502</td>\n",
       "      <td>0.18556</td>\n",
       "      <td>-0.19213</td>\n",
       "      <td>0.34857</td>\n",
       "      <td>-1.26894</td>\n",
       "      <td>-0.09497</td>\n",
       "      <td>-0.13900</td>\n",
       "      <td>0.22285</td>\n",
       "      <td>-0.95730</td>\n",
       "      <td>-0.29454</td>\n",
       "      <td>0.52474</td>\n",
       "      <td>-0.38825</td>\n",
       "      <td>-0.30067</td>\n",
       "      <td>-0.37793</td>\n",
       "      <td>0.56638</td>\n",
       "      <td>-0.18909</td>\n",
       "      <td>-0.60340</td>\n",
       "      <td>-1.36886</td>\n",
       "      <td>-0.49136</td>\n",
       "      <td>-1.71113</td>\n",
       "      <td>-0.98213</td>\n",
       "      <td>-0.92987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.38727</td>\n",
       "      <td>0.18556</td>\n",
       "      <td>-0.19213</td>\n",
       "      <td>0.34857</td>\n",
       "      <td>0.78806</td>\n",
       "      <td>-0.09497</td>\n",
       "      <td>-0.13900</td>\n",
       "      <td>0.22285</td>\n",
       "      <td>-0.95730</td>\n",
       "      <td>-0.29454</td>\n",
       "      <td>0.52474</td>\n",
       "      <td>-0.38825</td>\n",
       "      <td>-0.30067</td>\n",
       "      <td>-0.37793</td>\n",
       "      <td>0.56638</td>\n",
       "      <td>-0.18909</td>\n",
       "      <td>-0.60340</td>\n",
       "      <td>0.73053</td>\n",
       "      <td>-0.49136</td>\n",
       "      <td>0.58441</td>\n",
       "      <td>-0.98213</td>\n",
       "      <td>-0.92987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.12802</td>\n",
       "      <td>0.18556</td>\n",
       "      <td>-0.19213</td>\n",
       "      <td>0.34857</td>\n",
       "      <td>0.78806</td>\n",
       "      <td>-0.09497</td>\n",
       "      <td>-0.13900</td>\n",
       "      <td>0.22285</td>\n",
       "      <td>1.04461</td>\n",
       "      <td>-0.29454</td>\n",
       "      <td>0.52474</td>\n",
       "      <td>-0.38825</td>\n",
       "      <td>-0.30067</td>\n",
       "      <td>-0.37793</td>\n",
       "      <td>0.56638</td>\n",
       "      <td>-0.18909</td>\n",
       "      <td>1.65727</td>\n",
       "      <td>0.73053</td>\n",
       "      <td>-0.49136</td>\n",
       "      <td>0.58441</td>\n",
       "      <td>1.01820</td>\n",
       "      <td>1.07542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.46000</td>\n",
       "      <td>0.18556</td>\n",
       "      <td>5.20489</td>\n",
       "      <td>0.34857</td>\n",
       "      <td>0.78806</td>\n",
       "      <td>10.52992</td>\n",
       "      <td>7.19417</td>\n",
       "      <td>0.22285</td>\n",
       "      <td>1.04461</td>\n",
       "      <td>3.39515</td>\n",
       "      <td>0.52474</td>\n",
       "      <td>2.57568</td>\n",
       "      <td>3.32586</td>\n",
       "      <td>2.64598</td>\n",
       "      <td>0.56638</td>\n",
       "      <td>5.28855</td>\n",
       "      <td>1.65727</td>\n",
       "      <td>0.73053</td>\n",
       "      <td>2.03515</td>\n",
       "      <td>0.58441</td>\n",
       "      <td>1.01820</td>\n",
       "      <td>1.07542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration_as_adoptable   hasimage   hasvideo  spayed_neutered  house_trained   declawed  special_needs  shots_current  gender_Male  size_Large  size_Medium  size_Small  coat_Long  coat_Medium  coat_Short  coat_unknown  goodwith_children_True  goodwith_children_unknown  goodwith_dogs_True  goodwith_dogs_unknown  goodwith_cats_True  goodwith_cats_unknown\n",
       "count             6489.00000 6489.00000 6489.00000       6489.00000     6489.00000 6489.00000     6489.00000     6489.00000   6489.00000  6489.00000   6489.00000  6489.00000 6489.00000   6489.00000  6489.00000    6489.00000              6489.00000                 6489.00000          6489.00000             6489.00000          6489.00000             6489.00000\n",
       "mean                 0.00000   -0.00000   -0.00000         -0.00000        0.00000    0.00000       -0.00000        0.00000     -0.00000    -0.00000      0.00000     0.00000    0.00000     -0.00000    -0.00000       0.00000                -0.00000                   -0.00000            -0.00000                0.00000             0.00000               -0.00000\n",
       "std                  1.00008    1.00008    1.00008          1.00008        1.00008    1.00008        1.00008        1.00008      1.00008     1.00008      1.00008     1.00008    1.00008      1.00008     1.00008       1.00008                 1.00008                    1.00008             1.00008                1.00008             1.00008                1.00008\n",
       "min                 -0.69010   -5.38903   -0.19213         -2.86887       -1.26894   -0.09497       -0.13900       -4.48741     -0.95730    -0.29454     -1.90570    -0.38825   -0.30067     -0.37793    -1.76561      -0.18909                -0.60340                   -1.36886            -0.49136               -1.71113            -0.98213               -0.92987\n",
       "25%                 -0.59502    0.18556   -0.19213          0.34857       -1.26894   -0.09497       -0.13900        0.22285     -0.95730    -0.29454      0.52474    -0.38825   -0.30067     -0.37793     0.56638      -0.18909                -0.60340                   -1.36886            -0.49136               -1.71113            -0.98213               -0.92987\n",
       "50%                 -0.38727    0.18556   -0.19213          0.34857        0.78806   -0.09497       -0.13900        0.22285     -0.95730    -0.29454      0.52474    -0.38825   -0.30067     -0.37793     0.56638      -0.18909                -0.60340                    0.73053            -0.49136                0.58441            -0.98213               -0.92987\n",
       "75%                  0.12802    0.18556   -0.19213          0.34857        0.78806   -0.09497       -0.13900        0.22285      1.04461    -0.29454      0.52474    -0.38825   -0.30067     -0.37793     0.56638      -0.18909                 1.65727                    0.73053            -0.49136                0.58441             1.01820                1.07542\n",
       "max                  5.46000    0.18556    5.20489          0.34857        0.78806   10.52992        7.19417        0.22285      1.04461     3.39515      0.52474     2.57568    3.32586      2.64598     0.56638       5.28855                 1.65727                    0.73053             2.03515                0.58441             1.01820                1.07542"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df = pd.DataFrame(scaled, columns=df.columns)\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df.drop(columns='duration_as_adoptable'), \n",
    "                                                    scaled_df.duration_as_adoptable, test_size=0.3, \n",
    "                                                    random_state=192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4542, 21), (1947, 21))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4542,), (1947,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/cats_X_train.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/cats_X_test.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/cats_y_train.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"data/tt_sets/cats_y_test.csv\"\n"
     ]
    }
   ],
   "source": [
    "# save training and test sets\n",
    "datapath = 'data/tt_sets'\n",
    "save_file(X_train, 'cats_X_train.csv', datapath)\n",
    "save_file(X_test, 'cats_X_test.csv', datapath)\n",
    "save_file(y_train, 'cats_y_train.csv', datapath)\n",
    "save_file(y_test, 'cats_y_test.csv', datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "### Goal: Build two to three different models and identify the best one.\n",
    "<ul><li>Fit your models with a training dataset</li>\n",
    "<li>Review model outcomes â Iterate over additional models as needed</li>\n",
    "<li>Identify the final model that you think is the best model for this project</li></ul>\n",
    " Review the following questions and apply them to your analysis: \n",
    "<ul><li>Does my data involve a time series or forecasting? If so, am I splitting the train and test data appropriately?</li>\n",
    "<li>Is my response variable continuous or categorical?</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28022101654450216"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04154004, -0.0634057 , -0.03013522, -0.05800202, -0.02311485])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv = cross_validate(rf, X_train, y_train, cv=5)\n",
    "rf_cv_scores_preopt = rf_cv['test_score']\n",
    "rf_cv_scores_preopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.04323956807661937, 0.015519145990820903)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rf_cv_scores_preopt), np.std(rf_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.016057\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)\n",
    "rmse_rf_preopt = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "print(\"RMSE : % f\" %(rmse_rf_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "rf_grid_params = {\n",
    "        'n_estimators': n_est,\n",
    "        'max_depth': [1, 2, 3,4,5, 6,7,8,9, 10, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 33}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gcv = GridSearchCV(rf, param_grid=rf_grid_params, cv=5, n_jobs=-1)\n",
    "gcv.fit(X_train, y_train)\n",
    "gcv_params = gcv.best_params_\n",
    "\n",
    "gcv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09263920135465187"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=gcv_params['n_estimators'], max_depth=gcv_params['max_depth'])\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03536285, 0.04451424, 0.02745935, 0.02819064, 0.0635326 ]),\n",
       " array([ 0.08214884, -0.00019013,  0.00336443,  0.0437824 ,  0.05522162]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_train = cross_validate(rf, X_train, y_train, cv=5)\n",
    "rf_cv_test = cross_validate(rf, X_test, y_test, cv=5)\n",
    "rf_cv_train['test_score'], rf_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.03981193771133849\n",
      "Average CV Score, Trest Set: 0.036865433556144155\n"
     ]
    }
   ],
   "source": [
    "rf_train_score = np.mean(rf_cv_train['test_score'])\n",
    "rf_test_score = np.mean(rf_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", rf_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", rf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.957126\n",
      "RMSE Test Set :  0.967372\n"
     ]
    }
   ],
   "source": [
    "rf_train_pred = rf.predict(X_train)\n",
    "rf_test_pred = rf.predict(X_test)\n",
    "rf_rmse_train = np.sqrt(mean_squared_error(y_train, rf_train_pred))\n",
    "rf_rmse_test = np.sqrt(mean_squared_error(y_test, rf_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(rf_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(rf_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10238353196836003"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03195834, 0.03738974, 0.00158063, 0.02128292, 0.07123569])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv = cross_validate(gb, X_train, y_train, cv=5)\n",
    "gb_cv_scores_preopt = gb_cv['test_score']\n",
    "gb_cv_scores_preopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.032689464130200394, 0.02283114992512402)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gb_cv_scores_preopt), np.std(gb_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.970343\n"
     ]
    }
   ],
   "source": [
    "gb_pred = gb.predict(X_test)\n",
    "rmse_gb_preopt = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
    "print(\"RMSE : % f\" %(rmse_gb_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "gb_grid_params = {\n",
    "        'learning_rate': [.01, .1, 1],\n",
    "        'n_estimators': n_est,\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
       "                         'n_estimators': [10, 12, 16, 20, 26, 33, 42, 54, 69,\n",
       "                                          88, 112, 143, 183, 233, 297, 379, 483,\n",
       "                                          615, 784, 1000]})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid_cv = GridSearchCV(gb, param_grid=gb_grid_params, cv=5, n_jobs=-1)\n",
    "gb_grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 233}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid_cv.fit(X_train, y_train)\n",
    "gb_grid_cv_params = gb_grid_cv.best_params_\n",
    "\n",
    "gb_grid_cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11998736211015615"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=gb_grid_cv_params['n_estimators'], max_depth=gb_grid_cv_params['max_depth'], learning_rate=gb_grid_cv_params['learning_rate'])\n",
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03422109, 0.05303427, 0.03193368, 0.02558954, 0.07327393]),\n",
       " array([ 0.04537863,  0.00418906, -0.02305856, -0.00879617,  0.02782891]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cv_train = cross_validate(gb, X_train, y_train, cv=5)\n",
    "gb_cv_test = cross_validate(gb, X_test, y_test, cv=5)\n",
    "gb_cv_train['test_score'], gb_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.04361050048905235\n",
      "Average CV Score, Trest Set: 0.009108376068991819\n"
     ]
    }
   ],
   "source": [
    "gb_train_score = np.mean(gb_cv_train['test_score'])\n",
    "gb_test_score = np.mean(gb_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", gb_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", gb_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.942592\n",
      "RMSE Test Set :  0.969775\n"
     ]
    }
   ],
   "source": [
    "gb_train_pred = gb.predict(X_train)\n",
    "gb_test_pred = gb.predict(X_test)\n",
    "gb_rmse_train = np.sqrt(mean_squared_error(y_train, gb_train_pred))\n",
    "gb_rmse_test = np.sqrt(mean_squared_error(y_test, gb_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(gb_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(gb_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2894233765528853"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsRegressor(n_neighbors=25, weights='distance')\n",
    "kn.fit(X_train, y_train)\n",
    "kn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.07995864867532503, 0.02796840303593154)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_cv = cross_validate(kn, X_train, y_train, cv=5)\n",
    "kn_cv_scores_preopt = kn_cv['test_score']\n",
    "np.mean(kn_cv_scores_preopt), np.std(kn_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.026044\n"
     ]
    }
   ],
   "source": [
    "kn_pred = kn.predict(X_test)\n",
    "rmse_kn_preopt = np.sqrt(mean_squared_error(y_test, kn_pred))\n",
    "print(\"RMSE : % f\" %(rmse_kn_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "kn_grid_params = {\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'n_neighbors': n_est,\n",
    "        'p': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 88, 'p': 2, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_grid_cv = GridSearchCV(kn, param_grid=kn_grid_params, cv=5, n_jobs=-1)\n",
    "kn_grid_cv.fit(X_train, y_train)\n",
    "kn_grid_cv_params = kn_grid_cv.best_params_\n",
    "\n",
    "kn_grid_cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0503033369506809"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsRegressor(n_neighbors=kn_grid_cv_params['n_neighbors'], weights=kn_grid_cv_params['weights'], p=kn_grid_cv_params['p'])\n",
    "kn.fit(X_train, y_train)\n",
    "kn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00547563, 0.03781735, 0.02129488, 0.03582559, 0.05169464]),\n",
       " array([0.04565515, 0.0043644 , 0.01084321, 0.00673208, 0.03264615]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_cv_train = cross_validate(kn, X_train, y_train, cv=5)\n",
    "kn_cv_test = cross_validate(kn, X_test, y_test, cv=5)\n",
    "kn_cv_train['test_score'], kn_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.030421620622292478\n",
      "Average CV Score, Trest Set: 0.020048197767960095\n"
     ]
    }
   ],
   "source": [
    "kn_train_score = np.mean(kn_cv_train['test_score'])\n",
    "kn_test_score = np.mean(kn_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", kn_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", kn_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.979200\n",
      "RMSE Test Set :  0.968196\n"
     ]
    }
   ],
   "source": [
    "kn_train_pred = kn.predict(X_train)\n",
    "kn_test_pred = kn.predict(X_test)\n",
    "kn_rmse_train = np.sqrt(mean_squared_error(y_train, kn_train_pred))\n",
    "kn_rmse_test = np.sqrt(mean_squared_error(y_test, kn_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(kn_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(kn_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25096586468383075"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = 50)\n",
    "xg.fit(X_train, y_train)\n",
    "xg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.031572780704382984, 0.030081329946071083)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv = cross_validate(xg, X_train, y_train, cv=5)\n",
    "xg_cv_scores_preopt = xg_cv['test_score']\n",
    "np.mean(xg_cv_scores_preopt), np.std(xg_cv_scores_preopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1.026401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xg_pred = xg.predict(X_test)\n",
    "rmse_xg_preopt = np.sqrt(mean_squared_error(y_test, xg_pred))\n",
    "print(\"RMSE : % f\" %(rmse_xg_preopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "xg_grid_params = {\n",
    "        'objective': ['reg:squarederror', 'reg:squaredlogerror', 'reg:logistic'],\n",
    "        'n_estimators': n_est,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10, 'objective': 'reg:squarederror'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_grid_cv = GridSearchCV(xg, param_grid=xg_grid_params, cv=5, n_jobs=-1)\n",
    "xg_grid_cv.fit(X_train, y_train)\n",
    "xg_grid_cv_params = xg_grid_cv.best_params_\n",
    "\n",
    "xg_grid_cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16209205352834888"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = xgb.XGBRegressor(objective=xg_grid_cv_params['objective'], n_estimators = xg_grid_cv_params['n_estimators'])\n",
    "xg.fit(X_train, y_train)\n",
    "xg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.03400233, 0.04264221, 0.02116783, 0.00089932, 0.05557749]),\n",
       " array([ 0.03259394, -0.02276438, -0.00785386, -0.04212825,  0.02454441]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_train = cross_validate(xg, X_train, y_train, cv=5)\n",
    "xg_cv_test = cross_validate(xg, X_test, y_test, cv=5)\n",
    "xg_cv_train['test_score'], xg_cv_test['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Score, Training Set: 0.030857838012133442\n",
      "Average CV Score, Trest Set: -0.003121630468710679\n"
     ]
    }
   ],
   "source": [
    "xg_train_score = np.mean(xg_cv_train['test_score'])\n",
    "xg_test_score = np.mean(xg_cv_test['test_score'])\n",
    "\n",
    "print(\"Average CV Score, Training Set:\", xg_train_score)\n",
    "print(\"Average CV Score, Trest Set:\", xg_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training Set :  0.919766\n",
      "RMSE Test Set :  0.979553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xg_train_pred = xg.predict(X_train)\n",
    "xg_test_pred = xg.predict(X_test)\n",
    "xg_rmse_train = np.sqrt(mean_squared_error(y_train, xg_train_pred))\n",
    "xg_rmse_test = np.sqrt(mean_squared_error(y_test, xg_test_pred))\n",
    "print(\"RMSE Training Set : % f\" %(xg_rmse_train))\n",
    "print(\"RMSE Test Set : % f\" %(xg_rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV Train</th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>CV Test</th>\n",
       "      <th>RMSE Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.03981</td>\n",
       "      <td>0.95713</td>\n",
       "      <td>0.03687</td>\n",
       "      <td>0.96737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.04361</td>\n",
       "      <td>0.94259</td>\n",
       "      <td>0.00911</td>\n",
       "      <td>0.96978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNeighbors</th>\n",
       "      <td>0.03042</td>\n",
       "      <td>0.97920</td>\n",
       "      <td>0.02005</td>\n",
       "      <td>0.96820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.03086</td>\n",
       "      <td>0.91977</td>\n",
       "      <td>-0.00312</td>\n",
       "      <td>0.97955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CV Train  RMSE Train  CV Test  RMSE Test\n",
       "RandomForest       0.03981     0.95713  0.03687    0.96737\n",
       "GradientBoosting   0.04361     0.94259  0.00911    0.96978\n",
       "KNNeighbors        0.03042     0.97920  0.02005    0.96820\n",
       "XGBoost            0.03086     0.91977 -0.00312    0.97955"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = pd.DataFrame({'CV Train': [np.mean(rf_train_score), np.mean(gb_train_score), np.mean(kn_train_score), np.mean(xg_train_score)], 'RMSE Train': [rf_rmse_train, gb_rmse_train, kn_rmse_train, xg_rmse_train],'CV Test': [np.mean(rf_test_score), np.mean(gb_test_score), np.mean(kn_test_score), np.mean(xg_test_score)], 'RMSE Test': [rf_rmse_test, gb_rmse_test, kn_rmse_test, xg_rmse_test]}, index=['RandomForest', 'GradientBoosting', 'KNNeighbors', 'XGBoost'])\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best CV Score: \n",
      "Train: KNNeighbors \n",
      "Test: XGBoost\n",
      "\n",
      "Model with best RMSE: \n",
      "Train: XGBoost \n",
      "Test: RandomForest\n"
     ]
    }
   ],
   "source": [
    "print(\"Model with best CV Score: \\nTrain:\", model_scores['CV Train'].idxmin(), \"\\nTest:\", model_scores['CV Test'].idxmin())\n",
    "print(\"\\nModel with best RMSE: \\nTrain:\", model_scores['RMSE Train'].idxmin(), \"\\nTest:\", model_scores['RMSE Test'].idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['RandomForest', 'GradientBoosting', 'KNNeighbors', 'XGBoost','RandomForest', 'GradientBoosting', 'KNNeighbors', 'XGBoost']\n",
    "cv_scores_all = [np.mean(rf_train_score), np.mean(gb_train_score), np.mean(kn_train_score), np.mean(xg_train_score), np.mean(rf_test_score), np.mean(gb_test_score), np.mean(kn_test_score), np.mean(xg_test_score)]\n",
    "types = ['train', 'train', 'train', 'train', 'test', 'test', 'test', 'test']\n",
    "rmse_scores_all = [rf_rmse_train, gb_rmse_train, kn_rmse_train, xg_rmse_train, rf_rmse_test, gb_rmse_test, kn_rmse_test, xg_rmse_test]\n",
    "\n",
    "cv_scores = pd.DataFrame(list(zip(models, cv_scores_all, types)), \n",
    "               columns =['Model', 'Scores', 'Type' ]) \n",
    "rmse_scores = pd.DataFrame(list(zip(models, rmse_scores_all, types)), \n",
    "               columns =['Model', 'Scores', 'Type' ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig=plt.subplots(figsize=(10, 5))\n",
    "sns.barplot(x='Model', y='Scores', hue='Type', data=cv_scores)\n",
    "plt.title(\"CV Score Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.subplots(figsize=(10, 5))\n",
    "sns.barplot(x='Model', y='Scores', hue='Type', data=rmse_scores)\n",
    "plt.title(\"RMSE Score Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to go forward with **GradientBoosting** for the dogs data. I'm choosing this model because it has the best RMSE score for the test set, though I might tune an XGBoost model as well just to make sure it doesn't outperform on the test set if optimized further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
